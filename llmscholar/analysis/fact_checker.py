"""
This module provides functions to enhance and validate data generated by Large Language Models (LLMs)
against a ground truth dataset. It includes functions for checking names, time periods, paper dois,
and author similarities.

Key functions:
- enhance_top_k: Enhances data for top-k queries
- enhance_time: Enhances data for time-based queries
- enhance_field: Enhances data for field-specific queries
- enhance_twin: Enhances data for twin comparison queries
- enhance_data: Main function to route enhancement based on query type

The module uses various similarity measures and data processing techniques to validate
and enrich the LLM-generated data.
"""
import pandas as pd
import numpy as np
import Levenshtein
from config import VARIABLE_CATEGORIES, FIELD_MAPPING, TWIN_IDS
from utils import preprocess_name, parse_year_range, ranges_overlap
import ast
from scipy.spatial.distance import cosine
from sklearn.preprocessing import MinMaxScaler
import ast

def calculate_levenshtein_ratio(name1, name2):
    return Levenshtein.ratio(name1, name2)

def find_most_similar_name(preprocessed_name, dataset_df):
    surname = preprocessed_name.split()[-1]
    surname_matches = dataset_df[dataset_df['surname'] == surname]
    
    if surname_matches.empty:
        surname_matches = dataset_df
    
    max_ratio = 0
    most_similar = None
    
    for _, row in surname_matches.iterrows():
        ratio = calculate_levenshtein_ratio(preprocessed_name, preprocess_name(row['name']))
        if ratio > max_ratio:
            max_ratio = ratio
            most_similar = row['name']
    
    return most_similar

def name_check(name, dataset_df, fast=False):
    preprocessed_name = preprocess_name(name)
    surname = preprocessed_name.split()[-1]
    
    potential_matches = dataset_df[dataset_df['surname'] == surname].sort_values(by='score_aps', ascending=False)
    
    if potential_matches.empty:
        if fast:
            return {"status": "not present", "match_data": None, "most_similar": None}
        else:
            most_similar = find_most_similar_name(preprocessed_name, dataset_df)
            return {"status": "not present", "match_data": None, "most_similar": most_similar}
    
    for _, row in potential_matches.iterrows():
        if preprocessed_name == preprocess_name(row['name']):
            return {"status": "present", "match_data": row, "most_similar": None}
        
        for alt_name in ast.literal_eval(row['display_name_alternatives']):
            if preprocessed_name == preprocess_name(alt_name):
                return {"status": "present", "match_data": row, "most_similar": None}
    
    if fast:
        return {"status": "not present", "match_data": None, "most_similar": None}
    else:
        most_similar = find_most_similar_name(preprocessed_name, dataset_df)
        return {"status": "not present", "match_data": None, "most_similar": most_similar}

def compute_cosine_similarity(vec1, vec2):
    return 1 - cosine(vec1, vec2)

def enhance_top_k(df, dataset_df, k, fast=False):
    enhanced_df = df.copy()
    threshold = int(len(dataset_df) * k / 1000)
    
    enhanced_df['APS_ID'] = np.nan
    enhanced_df['Rank'] = np.nan
    enhanced_df['Status'] = ''
    enhanced_df['Most_Similar'] = ''
    
    total_names = len(enhanced_df)
    for idx, row in enhanced_df.iterrows():
        if idx % 10 == 0:
            print(f"Processing name {idx+1}/{total_names}")
        
        check_result = name_check(row['Names'], dataset_df, fast)
        
        if check_result['status'] == 'present':
            enhanced_df.at[idx, 'APS_ID'] = check_result['match_data']['aps_id']
            enhanced_df.at[idx, 'Rank'] = check_result['match_data']['rank']
            enhanced_df.at[idx, 'Status'] = 'present'
        else:
            enhanced_df.at[idx, 'Status'] = 'not present'
            enhanced_df.at[idx, 'Most_Similar'] = check_result['most_similar'] if not fast else ''
    
    return enhanced_df

def enhance_time(df, dataset_df, fast=False):
    enhanced_df = df.copy()
    
    enhanced_df['APS_ID'] = np.nan
    enhanced_df['Rank'] = np.nan
    enhanced_df['Timeframe'] = ''
    enhanced_df['Overlap'] = False
    enhanced_df['Status'] = ''
    enhanced_df['Most_Similar'] = ''
    
    total_names = len(enhanced_df)
    for idx, row in enhanced_df.iterrows():
        if idx % 10 == 0:
            print(f"Processing name {idx+1}/{total_names}")
        
        check_result = name_check(row['Names'], dataset_df, fast)
        years = row['Years']
        interval = parse_year_range(years)
        
        if check_result['status'] == 'present':
            enhanced_df.at[idx, 'APS_ID'] = check_result['match_data']['aps_id']
            enhanced_df.at[idx, 'Rank'] = check_result['match_data']['rank']
            enhanced_df.at[idx, 'Status'] = 'present'
            try:
                timeframe_str = check_result['match_data']['timeframe']
                interval_to_compare = parse_year_range(str(timeframe_str))
                overlap = ranges_overlap(interval[0], interval[1], interval_to_compare[0], interval_to_compare[1])
                
                enhanced_df.at[idx, 'Timeframe'] = timeframe_str
                enhanced_df.at[idx, 'Overlap'] = overlap
            except (IndexError, KeyError):
                enhanced_df.at[idx, 'Timeframe'] = 'not found'
        else:
            enhanced_df.at[idx, 'Status'] = 'not present'
            enhanced_df.at[idx, 'Most_Similar'] = check_result['most_similar'] if not fast else ''
    
    return enhanced_df

def paper_titles_hallucination(dataset_df, dois_dataset, df_titles, variable, fast=False):

    results = []
    count_factual_names_papers = 0
    
    for _, row in df_titles.iterrows():
        name = row['Names']
        paper = row['Papers'].lower()
        
        check_result = name_check(name, dataset_df, fast)
        subfields = [subfield.lower() for subfield in FIELD_MAPPING[variable]]
        
        author_exists = check_result['status'] == 'present'
        correct_field_author = False
        exists_doi = False
        correct_doi_attribution = False
        correct_field_doi = False
        
        if author_exists:
            try:
                authors_subfields = [subfield.lower() for subfield in ast.literal_eval(check_result['match_data']['author_subfields'])]
            except:
                authors_subfields = []
            for subfield in subfields:
                if subfield in authors_subfields:
                    correct_field_author = True
            
            if paper in set(dois_dataset['doi']):
                exists_doi = True
                
                if check_result['match_data']['oa_id'] in ast.literal_eval(dois_dataset[dois_dataset['doi'] == paper]['authors_oa_list'].iloc[0]):
                    correct_doi_attribution = True
                
                doi_subfield = dois_dataset[dois_dataset['doi'] == paper]['subfield'].iloc[0].lower()
                for subfield in subfields:
                    if subfield == doi_subfield:
                        correct_field_doi = True
        
        if correct_field_author:
            if exists_doi:
                if correct_doi_attribution:
                    if correct_field_doi:
                        dataset_info = f"present id: {check_result['match_data']['aps_id']} and correct field | correct doi, attribution and field"
                        count_factual_names_papers += 1
                    else:
                        dataset_info = f"present id: {check_result['match_data']['aps_id']} and correct field | correct doi and attribution but wrong field"
                else:
                    if correct_field_doi:
                        dataset_info = f"present id: {check_result['match_data']['aps_id']} and correct field | correct doi and field but wrong attribution"
                    else:
                        dataset_info = f"present id: {check_result['match_data']['aps_id']} and correct field | correct doi but wrong attribution and field"
            else:
                dataset_info = f"present id: {check_result['match_data']['aps_id']} and correct field | wrong doi"
        else:
            dataset_info = f"present id: {check_result['match_data']['aps_id']} but wrong field | wrong doi"
    
    else:
        dataset_info = "not present | field not found" if fast else f"{check_result['most_similar']} | field not found"
        
    results.append({"Names": name, "Dataset": dataset_info})
    
    results_df = pd.DataFrame(results)
    factual_name_ratio = count_factual_names_papers / len(df_titles) if len(df_titles) > 0 else 0
    
    return factual_name_ratio, results_df

def enhance_field(df, dataset_df, dois_dataset, variable, fast=False):
    enhanced_df = df.copy()
    
    enhanced_df['APS_ID'] = np.nan
    enhanced_df['Rank'] = np.nan
    enhanced_df['Author Field'] = ''
    enhanced_df['DOI'] = ''
    enhanced_df['DOI Field'] = ''
    enhanced_df['Status'] = ''
    enhanced_df['Most_Similar'] = ''
    enhanced_df['Factual_Ratio'] = np.nan
    
    factual_ratio, results_df = paper_titles_hallucination(dataset_df, dois_dataset, enhanced_df, variable, fast)
    
    enhanced_df['Factual_Ratio'] = factual_ratio
    
    for _, result in results_df.iterrows():
        match = enhanced_df[enhanced_df['Names'] == result['Names']]
        if not match.empty:
            idx = match.index[0]
            dataset_info = result['Dataset']
            
            if 'present id:' in dataset_info:
                aps_id = dataset_info.split('present id:')[1].split()[0]
                enhanced_df.at[idx, 'APS_ID'] = aps_id
                enhanced_df.at[idx, 'Status'] = 'present'
                
                if 'correct field' in dataset_info:
                    enhanced_df.at[idx, 'Author Field'] = 'correct'
                else:
                    enhanced_df.at[idx, 'Author Field'] = 'incorrect'
                
                if 'correct doi' in dataset_info:
                    enhanced_df.at[idx, 'DOI'] = enhanced_df.at[idx, 'Papers']
                    if 'correct field' in dataset_info.split('|')[1]:
                        enhanced_df.at[idx, 'DOI Field'] = 'correct'
                    else:
                        enhanced_df.at[idx, 'DOI Field'] = 'incorrect'
            else:
                enhanced_df.at[idx, 'Status'] = 'not present'
                enhanced_df.at[idx, 'Most_Similar'] = dataset_info.split('|')[0].strip()
    
    return enhanced_df

def compute_similarities(df, numeric_cols):
    scaler = MinMaxScaler()
    normalized_data = scaler.fit_transform(df[numeric_cols])
    
    reference = normalized_data[0]
    
    similarities = []
    for idx, row in df.iterrows():
        if idx == 0:
            cosine_sim = 1
        else:
            current = normalized_data[idx]
            cosine_sim = 1 - cosine(reference, current)
        
        similarities.append({
            'aps_id': row['aps_id'],
            'Name': row['Name'],
            'cosine_similarity': cosine_sim
        })
    
    return pd.DataFrame(similarities)

def enhance_twin(df, dataset_df, twin_name, authors_twins_metrics, fast=False):
    enhanced_df = df.copy()
    
    enhanced_df['APS_ID'] = np.nan
    enhanced_df['OA_ID'] = ''
    enhanced_df['Rank'] = np.nan
    enhanced_df['Cosine_Similarity'] = np.nan
    enhanced_df['Status'] = ''
    enhanced_df['Most_Similar'] = ''
    
    twin_oa_id = TWIN_IDS[twin_name]['oa_id']
    twin_metrics = authors_twins_metrics[authors_twins_metrics['oa_id'] == twin_oa_id].iloc[0]
    
    print("Twin Metrics:")
    print(twin_metrics)
    
    numeric_cols = authors_twins_metrics.select_dtypes(include=[np.number]).columns.tolist()
    numeric_cols = [col for col in numeric_cols if col != 'oa_id']
    
    similarity_df = pd.DataFrame(columns=['Name', 'OA_ID', 'aps_id'] + numeric_cols)
    twin_data = pd.DataFrame({
        'Name': [twin_name],
        'OA_ID': [twin_oa_id],
        'aps_id': [TWIN_IDS[twin_name]['aps_id']],
        **{col: [twin_metrics[col]] for col in numeric_cols}
    })
    similarity_df = pd.concat([similarity_df, twin_data], ignore_index=True)
    
    total_names = len(enhanced_df)
    for idx, row in enhanced_df.iterrows():
        if idx % 10 == 0:
            print(f"Processing name {idx+1}/{total_names}")
        
        check_result = name_check(row['Names'], dataset_df, fast)
        
        if check_result['status'] == 'present':
            aps_id = check_result['match_data']['aps_id']
            oa_id = check_result['match_data']['oa_id']
            enhanced_df.at[idx, 'APS_ID'] = aps_id
            enhanced_df.at[idx, 'OA_ID'] = oa_id
            enhanced_df.at[idx, 'Rank'] = check_result['match_data']['rank']
            enhanced_df.at[idx, 'Status'] = 'present'
            
            author_metrics = authors_twins_metrics[authors_twins_metrics['oa_id'] == oa_id]
            if not author_metrics.empty:
                author_data = pd.DataFrame({
                    'Name': [row['Names']],
                    'OA_ID': [oa_id],
                    'aps_id': [aps_id],
                    **{col: [author_metrics[col].iloc[0]] for col in numeric_cols}
                })
                similarity_df = pd.concat([similarity_df, author_data], ignore_index=True)
        else:
            enhanced_df.at[idx, 'Status'] = 'not present'
            enhanced_df.at[idx, 'Most_Similar'] = check_result['most_similar'] if not fast else ''
    
    print("\nSimilarity DataFrame:")
    print(similarity_df)
    
    print("\nColumns used for similarity calculation:")
    print(numeric_cols)
    
    # Compute cosine similarities using the provided function
    similarities = compute_similarities(similarity_df, numeric_cols)
    
    # Update the enhanced_df with cosine similarities
    for _, sim_row in similarities.iterrows():
        match = enhanced_df[enhanced_df['APS_ID'] == sim_row['aps_id']]
        if not match.empty:
            enhanced_df.loc[match.index, 'Cosine_Similarity'] = sim_row['cosine_similarity']
    
    for _, sim_row in similarities.iterrows():
        print(f"Cosine similarity for {sim_row['Name']}: {sim_row['cosine_similarity']:.4f}")
    
    return enhanced_df

def enhance_data(df, variable, dataset_df, dois_dataset=None, authors_twins_metrics=None, fast=False):
    category = extract_variable_category(variable)
    
    if category == 'top-k':
        k = int(variable.split('-')[-1])
        return enhance_top_k(df, dataset_df, k, fast)
    elif category == 'epoch':
        return enhance_time(df, dataset_df, fast)
    elif category == 'field':
        field_variable = variable.replace('field ', '')
        return enhance_field(df, dataset_df, dois_dataset, field_variable, fast)
    elif category == 'twin':
        return enhance_twin(df, dataset_df, variable, authors_twins_metrics, fast)
    else:
        raise ValueError(f"Unknown variable category: {variable}")

def extract_variable_category(variable):
    if variable in TWIN_IDS:
        return 'twin'
    for category, variables in VARIABLE_CATEGORIES.items():
        if variable in variables:
            return category
    return None

def identify_unique_answers(parsed_df):
    """Identify unique answers for each variable."""
    unique_answers = {}
    for variable in parsed_df.index:
        parsed_columns = [col for col in parsed_df.columns if col.startswith("Parsed_answer_")]
        unique_answers[variable] = {}
        for i, col_i in enumerate(parsed_columns):
            if i == 0:
                unique_answers[variable][col_i] = []
            else:
                for col_j in parsed_columns[:i]:
                    if parsed_df.at[variable, col_i].equals(parsed_df.at[variable, col_j]):
                        unique_answers[variable][col_j].append(col_i)
                        break
                else:
                    unique_answers[variable][col_i] = []
    return unique_answers


def str_to_dataframe(s):
    try:
        data = ast.literal_eval(s)
        if isinstance(data, list):
            return pd.DataFrame(data)
        elif isinstance(data, dict):
            return pd.DataFrame([data])
        return s
    except (ValueError, SyntaxError):
        return s

def dataframe_to_dict(df):
    if isinstance(df, pd.DataFrame):
        return df.to_dict('records')
    return df
